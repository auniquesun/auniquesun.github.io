---
layout: post
title: MarrNet
tags: [Computer Vision, 3D Shape Reconstruction, 2.5D Sketch]
gh-repo: jiajunwu/marrnet
gh-badge: [star, fork, follow]
mathjax: true
comments: true
---

* 论文名称：[MarrNet: 3D Shape Reconstruction via 2.5D Sketches](https://jiajunwu.com/papers/marrnet_nips.pdf)

* 论文作者：Jiajun Wu, Yifan Wang, Tianfan Xue, Xingyuan Sun, William T. Freeman, Joshua B. Tenenbaum（MIT CSAIL, ShanghaiTech University）

* 收录情况：NeurIPS 2017

### 简介
（？？？为什么称作2.5D）

### 主要方法
![](../img/post/marrnet_fig2.png)

MarrNet 包含3个部分：
* 2.5D sketch estimator
* 3D shape estimator

* projection consistency function
    - 通过设计损失函数，使得估计的3D物体结构和推理的2.5D sketch保持一致

1. 2.5D Sketch Estimation
    - input: 2D rgb image
    - output: 2.5D sketch，由几个维度刻画
        * 物体表面法向量
        * （像素）深度值
        * 物体轮廓图 —— silhouette

    - 使用2.5D轮廓估计的目的是仅保留物体本身的特征（形状、深度、大小），去掉环境因素（光照、背景） —— **蒸馏**
    - 采用 encoder-decoder 架构进行 2.5D sketch 估计
        * 编码器是 ResNet-18，把256x256的图片，编码成512个8x8的特征图
        * 解码器包含4个这样的block：5x5 全卷积 + ReLU activation

2. 3D Shape Estimation
    - input: surface normal and depth image（这些东西从2.5D sketch得到）
    - output: 3D object

    - 因为有了2.5D sketch，所以这部分能在合成数据上训练，而且不用担心domain adaption问题，但不足之处是生成的3D object，真实感不足，一看就是生成出来的

    - 同样采用encoder-decoder结构
        - encoder: 5个block（conv + ReLU + pooling）$\rightarrow$ $2~fc~ layers$
            * 参考 Girdhar et al., 2016
            - 把输入数据编码成 200 维向量，给到decoder
        - decoder: 5个block（conv + ReLU）$\rightarrow$ $128 \times 128$ voxel-based reconstruction of the input
            * 参考 Wu et al., 2016b

3. Reprojection Consistency
    - 一些基于神经网络的方法，强制加入 估计的3D形状 和 2D表示 的一致性约束（一般是通过损失函数）
    - 本文也加入3D shape和2.5D sketch之间的一致性约束，共有两项
        * depth reprojection loss
        * surface normal reprojection loss
    - 一些形式化表示
        * $v_{x,y,z}$ 表示3D 体素网格中位置$(x,y,z)$对应的数值，且 $\any x,y,z v_{x,y,z} \in [0,1]$ 成立
        * $d_{x,y}$ 表示位置$(x,y)$对应的深度值(？？？我理解这是说的像素值)
        * $n_{x,y} = (n_a, n_b, n_c)$ 表示估计的表面法向量

    - 本文有一个重要假设：认为从3D到2D的投影是正交的（我理解为主投影，原文是We assume orthographic projection in this work）

    - Depth reprojection loss
        * 这部分损失函数，设计目标是让体素值 $v_{x,y,d_{x,y}}$ 为1，因为此时深度值正好等于 $d_{x,y}$，深度小于 $d_{x,y}$ 时，体素值为0
        * 具体的损失函数如下
            - ![](../img/post/marrnet_eq1.png)
        * 损失函数对 $v_{x,y,z}$ 的导数
            - ![](../img/post/marrnet_eq2.png)
        - 当 $d_{x,y} = \inf$ 时，深度值进入一种特殊情况 —— 形状轮廓（？？？没理解这个因果关系）
            - 当线段与形状没有交集时，体素值应当全为0
            - ![](../img/post/planerecover_fig2.png)
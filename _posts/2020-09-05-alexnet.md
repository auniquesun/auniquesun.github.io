---
layout: post
title: AlexNet
tags: [Computer Vision, Image Recognition, AlexNet]
gh-repo: pytorch/vision
gh-badge: [star, fork, follow]
mathjax: true
comments: true
---
今天分享的这篇论文发表时间是2012年，算是比较早了，是把深度卷积神经网络成功应用在计算机视觉领域的开山之作，目前被引用量接近 70000，可见影响力非常之大，可以说做视觉的论文十有八九会引用它。网络上对它的讲解非常之多，再拿出来阅读，是因为它很经典，搞清楚深度卷积神经网络一些最基本的东西。

* 论文标题：[ImageNet Classification with Deep Convolutional Neural Networks](https://dl.acm.org/doi/10.1145/3065386)

* 论文作者：Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton（多伦多大学）

* 收录情况：NIPS 2012

这篇论文提出的神经网络被称为 AlexNet，它的成名源于一个视觉识别竞赛 ImageNet Large Scale Vision Recognition Challenge (ILSVRC)——2010年开办，每年一次，2017年年结束。ImageNet是一个计算机视觉领域的公开数据集，规模非常之大——涵盖22000个类别的1500万张标注图片，目的是让研究人员的算法在上面做实验，

* Image Classification
* Object Detection
* Semantic Segmentation

比较不同算法的优劣，促进视觉研究的进步。ILSVRC 使用的是 ImageNet 的一部分数据，包含~120万张图片，分成1000类，每类~1200张图片，划分成训练集（100万张标注图片）、验证集（5万张标注图片，用于自己评估算法效果）、测试集（15万张无标签图片，预测结果提交到主办方评估）参赛者需要开发算法把测试集图片分到正确的类别。这其实是个比较困难的任务。

### 简介
* AlexNet 是一个8层的神经网络，5个卷积层 + 3个全连接层
* 几个创新点 —— 现在看来是 tricks：
    * 激活函数使用 ReLU
    * 分布式训练 —— 使用了两块GPU
    * 使用 Normalization
    * 使用 Overlapping Pooling
    * Dropout 应用到了全连接层
* 现在看似很简单，实际上经历了长期探索

### 模型结构
![](../img/post/alexnet_f2.png)
* 输入：224 x 224 的RGB图片
* 输出：1000维的向量，每维表示对应类别的概率
* 参数量计算
    * 明确哪些层里包含参数
    * 参数存在于**卷积层**和**全连接层**

| Layer       | Kernel     | #Weights     | #Biases     | #Parameters     |
| :------------- | :----------: | -----------: | -----------: | -----------: |
|  Input Image | 224x224x3   | 0    | 0   | 0 |
| Conv-1	| (11x11x3)x96	| 34,848	| 96	| 34,944 |
| Conv-2	| (5x5x48)x256	| 614,400 	| 256	| 614,656 |
| Conv-3	| (3x3x256)x384	| 884,736	| 384    |	885,120 |
| Conv-4	| (3x3x192)x384	| 1,327,104	| 384	|1,327,488 |
| Conv-5	| (3x3x192)x256	| 884,736	| 256	|884,992
| FC-1	| 4096×1	| 37,748,736|	4,096 |	37,752,832 |
| FC-2	| 4096×1	| 16,777,216|	4,096 |	16,781,312 |
| FC-3	| 1000×1	| 4,096,000	|   1,000 | 4,097,000 |
| Total	| - | - | - | - |		62,378,344|

### 实验
* 评价指标：top-1、top-5 error rate
    * top-1 error rate：对于测试集的每张图片，预测输出1000维的向量，其中最大的值对应的类别即为预测的类别，和真实类别比较的错误率
    * top-5 error rate：对于测试集的每张图片，预测输出1000维的向量，其中最大的top-5个值对应的类别即为预测的类别，如果包含真实类别，就算预测正确，否则错误，由此计算的错误率
* ![](../img/post/alexnet_t1.png)
* ![](../img/post/alexnet_t2.png)
* 使用不同的激活函数，神经网络预测错误率下降速度对比
    ![](../img/post/alexnet_f1.png)
    * 一个4层的卷积神经网络，在CiFAR-10上训练，虚线是使用 tanh 激活函数，实线是用 ReLU 激活函数
    * 使用 ReLU 激活函数比 tanh 快6倍，后一个激活函数计算量大

### PyTorch 实现
```python
import torch
import torch.nn as nn

class AlexNet(nn.Module):

    def __init__(self, num_classes=1000):
        super(AlexNet, self).__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 48, kernel_size=11, stride=4, padding=2),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2),
            nn.Conv2d(48, 128, kernel_size=5, padding=2),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2),
            nn.Conv2d(128, 384, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(384, 384, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(384, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2),
        )
        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))
        self.classifier = nn.Sequential(
            nn.Dropout(),
            nn.Linear(256 * 6 * 6, 4096),
            nn.ReLU(inplace=True),
            nn.Dropout(),
            nn.Linear(4096, 4096),
            nn.ReLU(inplace=True),
            nn.Linear(4096, num_classes),
        )

    def forward(self, x):
        x = self.features(x)
        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        x = self.classifier(x)
        return x
```
加载图片、训练、预测、评估的代码，都要补充完整；最后自己亲身试验一遍
---
layout: post
title: AlexNet
tags: [Computer Vision, Image Recognition, AlexNet]
gh-repo: pytorch/vision
gh-badge: [star, fork, follow]
mathjax: true
comments: true
---
今天分享的这篇论文发表时间是2012年，算是比较早了，是把深度卷积神经网络成功应用在计算机视觉领域的开山之作，目前被引用量接近 70000，可见影响力非常之大，可以说做视觉的论文十有八九会引用它。网络上对它的讲解非常之多，再拿出来阅读，是因为它很经典，搞清楚深度卷积神经网络一些最基本的东西。

* 论文标题：[ImageNet Classification with Deep Convolutional Neural Networks](https://dl.acm.org/doi/10.1145/3065386)

* 论文作者：Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton 
    - from University of Toronto

* 收录情况：NIPS 2012

这篇论文提出的神经网络被称为 AlexNet，它的成名源于一个视觉识别竞赛 ImageNet Large Scale Vision Recognition Challenge (ILSVRC)——2010年开办，每年一次，2017年年结束。ImageNet是一个计算机视觉领域的公开数据集，规模非常之大——涵盖22000个类别的1500万张标注图片，目的是让研究人员的算法在上面做实验，

* Image Classification
* Object Detection
* Semantic Segmentation

比较不同算法的优劣，促进视觉研究的进步。ILSVRC 使用的是 ImageNet 的一部分数据，包含~120万张图片，分成1000类，每类~1200张图片，划分成训练集（100万张标注图片）、验证集（5万张标注图片，用于自己评估算法效果）、测试集（15万张无标签图片，预测结果提交到主办方评估）参赛者需要开发算法把测试集图片分到正确的类别。这其实是个比较困难的任务。

### 简介
* AlexNet 是一个8层的神经网络，5个卷积层 + 3个全连接层
* 几个创新点 —— 现在看来是 tricks：
    * 激活函数使用 ReLU
    * 分布式训练 —— 使用了两块GPU
    * 使用 Normalization
    * 使用 Overlapping Pooling
    * Dropout 应用到了全连接层
* 现在看似很简单，实际上经历了长期探索

### 模型结构
![](../img/post/alexnet_f2.png)
* 输入：224 x 224 的RGB图片
* 输出：1000维的向量，每维表示对应类别的概率

### 实验
* 评价指标：top-1、top-5 error rate
    * top-1 error rate：对于测试集的每张图片，预测输出1000维的向量，其中最大的值对应的类别即为预测的类别，和真实类别比较的错误率
    * top-5 error rate：对于测试集的每张图片，预测输出1000维的向量，其中最大的top-5个值对应的类别即为预测的类别，如果包含真实类别，就算预测正确，否则错误，由此计算的错误率
* ![](../img/post/alexnet_t1.png)
* ![](../img/post/alexnet_t2.png)

### PyTorch 实现
```python
import torch
import torch.nn as nn

class AlexNet(nn.Module):

    def __init__(self, num_classes=1000):
        super(AlexNet, self).__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 48, kernel_size=11, stride=4, padding=2),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2),
            nn.Conv2d(48, 128, kernel_size=5, padding=2),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2),
            nn.Conv2d(128, 384, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(384, 384, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(384, 256, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=2),
        )
        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))
        self.classifier = nn.Sequential(
            nn.Dropout(),
            nn.Linear(256 * 6 * 6, 4096),
            nn.ReLU(inplace=True),
            nn.Dropout(),
            nn.Linear(4096, 4096),
            nn.ReLU(inplace=True),
            nn.Linear(4096, num_classes),
        )

    def forward(self, x):
        x = self.features(x)
        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        x = self.classifier(x)
        return x
```
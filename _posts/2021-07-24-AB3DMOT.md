---
layout: post
title: 3D Multi-Object Tracking - A Baseline and New Evaluation Metrics
tags: [3D MOT, 3D Kalman Filter, Hungarian algorithm, Baseline, New Evaluation Metrics]
gh-repo: xinshuoweng/AB3DMOT
gh-badge: [star, fork, follow]
mathjax: true
comments: true
---

* 论文名称：[3D Multi-Object Tracking: A Baseline and New Evaluation Metrics](https://ieeexplore.ieee.org/document/9341164)

- 论文作者：Xinshuo Weng, Jianren Wang, David Held and Kris Kitani

- 收录情况：IROS 2020

### 简介
![](../img/post/ab3dmot_fig2.png)

3D多目标跟踪系统，更多时候关注系统的准确性，对系统复杂度和计算开销考虑较少，而这些方面对于3D跟踪系统的可用性非常重要。本文与其他工作形成鲜明对比，仅用简单的方法，使跟踪系统达到实时的运行效率。

AB3DMOT利用PointRCNN，从3D点云获得物体检测结果，然后组合 3D Kalman Filter 和 Hungarian algorithm进行**状态估计**和**数据关联**，没有像主流方法那样用深度神经网络做，所以系统非常高效（不计3D检测，207.4 FPS）。

另外一个重要的创新点：已有的KITTI数据集，其实是在2D 图像平面评价3D MOT系统，有些错位的感觉，目前仍然缺乏3D MOT evaluation metrics，本文提出了3D MOT evaluation tools，评价3D MOT系统在3D空间的表现。基于新的评价指标，AB3DMOT达到了最好的效果(:。

### 主要方法
![](../img/post/ab3dmot_fig2.png)

AB3DMOT 由以下几个步骤组成
* 3D Object Detection
* 3D Kalman Filter: State Prediction
* Data Association
* 3D Kalman Filter: State Update
* Birth and Death Memory

1. 3D Object Detection
    - 使用PointRCNN
    - $t$时刻的检测结果 $D_t = \{D_t^1, D_t^1, \cdots, D_t^{n_t}\}$
    - 对于 $D_t^j, j\in\{1,2,\cdots,n_t\}$，表示为以下元组
        - $(x,y,z,\theta,l,w,h,s)$
        - 物体中心位置$(x,y,z)$
        - 物体尺寸$(l,w,h)$
        - 朝向角$\theta$
        - 置信度分数$s$

    - 3D object检测器的好坏，必然对3D MOT的表现有影响

2. 3D Kalman Filter: State Prediction
    - 这一步要根据前一帧信息，预测物体下一帧**物体轨迹的状态**
    - 本文假设运动模型中速度是恒定不变的，独立于相机自身运动，即仅用运动模型估计相机自身和其他物体的运动
    - **物体轨迹的状态**用向量$T$描述
        - $(x,y,z,\theta,l,w,h,s,v_x,v_y,v_z)$
        - 物体在3D空间的速度：$v_x,v_y,v_z$
        - $T$中不包含角速$v_\{theta}$，是为了简化问题，作者说加上$v_\{theta}$对跟踪表现提升不明显

    - 前一帧物体轨迹的状态 $T_{t-1} = \{ T_{t-1}^1, T_{t-1}^2, \cdots, T_{t-1}^{m_{t-1}} \}$
        - $m_{t-1}$ 是第$t-1$帧中物体轨迹数
        - 经过3D Kalman Filter**预测**，得到第$t$帧的轨迹$T_{est}$
        - 运动模型
            - $x_{est} = x + v_x, y_{est} = y + v_y, z_{est} = z + v_z$
    
    - 因此，对于 $T_{t-1}^i \in T_{t-1}, i\in{1,2,\cdots,m_{t-1}}$，它在第t帧预测的状态是$T_{est} = (x_{est},y_{est},z_{est},\theta,l,w,h,s,v_x,v_y,v_z)$
    